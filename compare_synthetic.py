#!/usr/bin/env python3
# Name: Jon Akutagawa
# Date: 18-12-28

"""
This script loads VCF files generated by variant callers and compares their
results. Variant callers were fed synthetic data with defined mutations, so
sensitivity and PPV can be measured. Metrics are output as graphs.

input: Two VCF files generated by paired data run on MuTect2, Platypus, or
VarDict

output:
scatter plot for sensitivity and PPV
histograms for depth and vaf of detected mutations

python compare_synthetic.py -s /scratch/jakutagawa/icgc/var_calls/mutect2/PCAWG.764a33dc-dd34-11e4-8a0c-117cc254ba06.STAR.v1.split.vcf \
 -n /scratch/jakutagawa/icgc/var_calls/mutect2/PCAWG.764a33dc-dd34-11e4-8a0c-117cc254ba06.STAR.v1.split.normal.vcf \
 -ml /private/groups/brookslab/jakutagawa/variant_calling/synthetic_mutation_lists/October_2016_whitelist_2583.snv_mnv_indel.random_snp_only2.txt

python compare_synthetic.py -s /scratch/jakutagawa/icgc/var_calls/mutect2/PCAWG.764a33dc-dd34-11e4-8a0c-117cc254ba06.STAR.v1.split.vcf \
/scratch/jakutagawa/icgc/var_calls/platypus/DO46933-synthetic.vcf \
/scratch/jakutagawa/icgc/var_calls/vardict/mutant/764a33dc-dd34-11e4-8a0c-117cc254ba06.out.vcf \
 -n /scratch/jakutagawa/icgc/var_calls/mutect2/PCAWG.764a33dc-dd34-11e4-8a0c-117cc254ba06.STAR.v1.split.normal.vcf \
 /scratch/jakutagawa/icgc/var_calls/platypus/DO46933.vcf \
 /scratch/jakutagawa/icgc/var_calls/vardict/normal/764a33dc-dd34-11e4-8a0c-117cc254ba06.out.vcf \
 -ml /private/groups/brookslab/jakutagawa/variant_calling/synthetic_mutation_lists/October_2016_whitelist_2583.snv_mnv_indel.random_snp_only2.txt \
 -b /scratch/jakutagawa/icgc/bams/normal/DO46933/PCAWG.764a33dc-dd34-11e4-8a0c-117cc254ba06.STAR.v1.bam
"""

import sys
from multiprocessing import Pool

import pysam

import numpy as np
import matplotlib
matplotlib.use('Agg')
#import seaborn as sns; sns.set()
import matplotlib.pyplot as plt
import matplotlib.patches as mplpatches


mutect_depths = dict()
dict_test = dict()

def load_mutation_list (mutation_list_filename,bam_filename):
    """
    Load mutations spiked into the synthetic data
    """
    #bamfile = pysam.AlignmentFile(bam_filename, "rb" )
    counter = 0
    mutations_dict = dict()

    for chrom,pos1,pos2,vaf,mut_base,mut_type in read_mutation_list(mutation_list_filename):
        counter += 1
        #new_base = mutation.split('>')[1]
        #mut_entry = (chrom,pos1,pos2,vaf,mut_base,mut_type)
        mut_entry = (chrom,pos1,mut_base)
        depth = get_coverage(bam_filename, mut_entry)
        mutations_dict[mut_entry] = (float(vaf), int(depth))
        #mutations_dict[mut_entry] = 1
        #vaf_dict[mut_entry] = vaf
        #if counter % 10000 == 0:
        #    sys.stderr.write('loaded ' + str(counter) + ' mutations \n')

    #print (mutations_list[0])
    sys.stderr.write('finished loading ' + mutation_list_filename + '\n')
    return mutations_dict


def load_vcf (vcf_filename):
    """
    Load VCF data into a list of tuples
    """
    counter = 0
    mutations_list = list()
    file_origin = get_file_origin(vcf_filename)
    #print (mutect_depths)

    for chrom,pos1,ref_base,var_base in read_vcf(vcf_filename,file_origin):
        counter += 1
        #new_base = mutation.split('>')[1]
        #mut_entry = (chrom,pos1,ref_base,var_base)
        mut_entry = (chrom,pos1,var_base)
        mutations_list.append(mut_entry)
        #if counter % 10000 == 0:
        #    sys.stderr.write('loaded ' + str(counter) + ' mutations \n')

    #print (mutations_list[0])

    #print (mutect_depths)
    print (dict_test)
    sys.stderr.write('finished loading ' + vcf_filename + '\n')
    return mutations_list

def get_file_origin(vcf_file):
    """
    Determine which variant caller generated the VCF
    """
    if 'mutect' in vcf_file.lower():
        file_origin = 'mutect'
    elif 'vardict' in vcf_file.lower():
        file_origin = 'vardict'
    elif 'platypus' in vcf_file.lower():
        file_origin = 'platypus'

    return file_origin

def read_vcf (vcf_filename,file_origin):
    """
    Read in VCF and parse line for necessary values.
    """
    #global mutect_depths

    with open(vcf_filename) as fileH:
        # read the header
        header_counter = 0
        while True:
            line = fileH.readline()
            header_counter += 1
            if not line.startswith('#'):
                break

        for line in fileH:
            if file_origin == 'vardict':
                split_line = line.rstrip().split(' \t ')
            else:
                split_line = line.rstrip().split('\t')
            chrom = split_line[0]
            try:
                pos1 = int(split_line[1])
            except ValueError:
                continue
                #sys.stderr.write('line begins with &\n')
            ref_base = split_line[3]
            var_base = split_line[4]
            info = split_line[7]
            split_info = info.split(';')


            if file_origin == 'mutect':
                for info_type in split_info:
                    if info_type.split('=')[0] == 'DP':
                        depth = info_type.split('=')[1]
                        mutect_depths[(chrom,pos1,var_base)] = depth
                        dict_test[1] = 'yo'
                        #print (depth)
                    if info_type.split('=')[0] == 'TLOD':
                        tlod = float(info_type.split('=')[1].split(',')[0])
                tumor_info = split_line[9]
                split_tumor_info = tumor_info.split(':')

            #if file_origin == 'platypus':



            if not line.startswith('&'):
                yield chrom,pos1,ref_base,var_base

#sys.stderr.write('finished loading ' + str(counter) + ' mutations \n')

def load_all_vcfs (file_list):
    """
    Read in all variants from VCF files simultaneously using Pool
    """
    p = Pool()
    vcf_lists = p.map(load_vcf, file_list)
    return vcf_lists

def read_mutation_list (mutation_list_filename):
    """
    Read in VCF and parse line for necessary values.
    """
    with open(mutation_list_filename) as fileH:
        for line in fileH:
            split_line = line.rstrip().split('\t')
            chrom = split_line[0]
            pos1 = int(split_line[1])
            pos2 = int(split_line[2])
            vaf = split_line[3]
            mut_base = split_line[4]
            mut_type = split_line[5]

            yield chrom,pos1,pos2,vaf,mut_base,mut_type

#sys.stderr.write('finished loading ' + str(counter) + ' mutations \n')

def find_differences (vcf_lists, spiked_mutation_dict, file_list, bam_filename):
    """
    Determine which variant calls are true and false positives. Prints
    sensitivity and PPV.
    """
    pairs = len(vcf_lists) / 2
    file_origins = list()
    ppv_list = list()
    sensitivity_list = list()

    for index in range(0,pairs):

        print ('total mutant calls: ' + str(len(vcf_lists[index])))
        print ('total normal calls: ' + str(len(vcf_lists[index+pairs])))
        false_negatives = list()
        possible_positives = list()
        false_positives = list()
        true_positives = list()

        false_negatives = list(set(spiked_mutation_dict.keys()) - set(vcf_lists[index]))
        possible_positives = list(set(vcf_lists[index]) - set(vcf_lists[index+pairs]))

        for positive in possible_positives:
            if positive in spiked_mutation_dict:
                true_positives.append(positive)
            else:
                #print (get_coverage(bam_filename,positive))
                false_positives.append(positive)



        ppv = float(len(true_positives)) / float(len(true_positives) + len(false_positives))
        ppv_list.append(ppv)
        sensitivity = float(len(true_positives)) / float(len(true_positives)+len(false_negatives))
        sensitivity_list.append(sensitivity)

        print ('sensitivity: ' + str(sensitivity))
        print ('ppv: ' + str(ppv))
        print ('false pos count: ' + str(len(false_positives)))
        file_origin = get_file_origin(file_list[index])
        file_origins.append(file_origin)
        #vaf_depth_histograms (spiked_mutation_dict, true_positives, false_negatives, false_positives, file_origin, bam_filename)

    sensitivity_ppv(sensitivity_list, ppv_list, file_origins)


def vaf_depth_histograms (spiked_mutation_dict, true_positives, false_negatives, false_positives, file_origin, bam_filename):
    """
    Output histograms showing vaf and depth of true positive and false negative
    mutations using matplotlib.
    """
    true_positive_vaf_list = list()
    false_negative_vaf_list = list()
    true_positive_depth_list = list()
    false_negative_depth_list = list()
    false_positive_depth_list = list()
    my_bins = np.arange(1, 501, step=25)
    my_log_bins = np.logspace(0,3,num=15,base=10)

    for mutation in true_positives:
        true_positive_vaf_list.append(spiked_mutation_dict[mutation][0])
        true_positive_depth_list.append(spiked_mutation_dict[mutation][1])

    for mutation in false_negatives:
        false_negative_vaf_list.append(spiked_mutation_dict[mutation][0])
        false_negative_depth_list.append(spiked_mutation_dict[mutation][1])

    for mutation in false_positives:
        depth = int(get_coverage(bam_filename, mutation))
        #if depth == 0:
        #    depth += 1
        #log_depth = np.log10(depth)
        false_positive_depth_list.append(depth)

    #print (false_positive_depth_list)

    #print ('yo')
    plt.figure(figsize=(6,3))
    panel1=plt.axes([0.05,0.175,2.25/6,2.275/3])
    panel2=plt.axes([0.55,0.175,2.25/6,2.275/3])
    #x_array_hist, bins = np.histogram(true_positive_depth_list, bins=11)
    #print (true_positive_depth_list)
    #print (x_array_hist)
    #print (bins)

    """
    x_array_hist, bins = np.histogram(vaf_list, bins=11)
    #print (x_array_hist)
    #print (bins)

    for step in np.arange(0,len(x_array_hist),1):
        left=bins[step]
        bottom=0
        width=bins[step+1]-bins[step]
        height=x_array_hist[step]

        rectangle1=mplpatches.Rectangle((left,bottom),width,height,\
                                        linewidth=0.1,\
                                        facecolor=(0.5,0.5,0.5),\
                                        edgecolor=(0,0,0))



        panel1.add_patch(rectangle1)
    """
    panel1.hist(true_positive_vaf_list, bins = 11, label = 'true positive')
    panel1.hist(false_negative_vaf_list, bins = 11, alpha = 0.5, label = 'false negative')
    panel2.hist(true_positive_depth_list, bins = my_log_bins, label = 'true positive')
    panel2.hist(false_negative_depth_list, bins = my_log_bins, alpha = 0.5, label = 'false negative')
    panel2.hist(false_positive_depth_list, bins = my_log_bins, alpha = 0.5, label = 'false positive')


    panel1.set_xlabel('vaf')
    panel2.set_xlabel('depth')
    panel2.legend(loc='upper right')
    panel2.set_xticks([1,10,100,1000])
    panel2.set_xticklabels([1,10,100,1000])
    #print(panel1.get_xticks)
    #print(panel1.get_xticklabels)

    plot_filename = file_origin + '_histograms-log.pdf'
    plt.savefig(plot_filename)


def sensitivity_ppv (sensitivity_list, ppv_list, file_origins):
    """
    Output a scatter plot comparing sensitivity and PPV of each tool.
    """
    plt.figure(figsize=(3,3))
    panel1=plt.axes([0.2,0.175,2.25/3,2.275/3])

    panel1.scatter(sensitivity_list, ppv_list, alpha = 0.5)
    for index, origin in enumerate(file_origins,0):
        panel1.text(sensitivity_list[index]*1.1, ppv_list[index], origin,
                    fontsize=8,
                    horizontalalignment='left',
                    verticalalignment='center')
    panel1.set_xlabel('sensitivity')
    panel1.set_ylabel('ppv')
    ticks = np.arange(0, 1.1, step=0.25)
    panel1.set_xticks(ticks)
    panel1.set_yticks(ticks)
    panel1.set_xticklabels(ticks)
    panel1.set_yticklabels(ticks)
    plt.savefig('sensitivity_vs_ppv.pdf')

def clean_mutation_list (mutation_dict, bam_filename, reference_fasta):
    """
    Remove mutations that have the same base as the spiked mutation
    """
    cleaned_mutation_dict = dict()
    removed_mutations = list()

    for mutation, vaf_depth in mutation_dict.items():
        chrom = mutation[0]
        pos1 = mutation[1]
        #pos2 = mutation[2]
        mut_base = mutation[2]
        location = chrom + ':' + str(pos1) + '-' + str(pos1)
        #pileup = pysam.mpileup("-O","-r", location, "-f", reference_fasta, bam_filename)
        faidx = pysam.faidx(reference_fasta, location)

        #print (pileup)
        #mutation_depth = pysam.depth("-r", location, bam_filename)
        mutation_depth = vaf_depth[1]
        #print ('for mutation: ' + str(mutation))
        #try:
        #    depth = mutation_depth.rstrip().split('\t')[2]
        #except IndexError:
        #    depth = 0

        ref_base = faidx.rstrip().split('\n')[1]
        #try:
        #    ref_base = pileup.rstrip().split('\t')[2]
        #except IndexError:
        #    ref_base = 0

        #print ('base')
        #print (ref_base)
        #print (mut_base)
        #print (depth)
        if mut_base == ref_base or mutation_depth == 0 or ref_base == 0:
            removed_mutations.append(mutation)
        else:
            cleaned_mutation_dict[mutation] = vaf_depth
    sys.stderr.write('removed ' + str(len(removed_mutations)) + 'mutations with 0 reads or trivial mutation\n')
    return cleaned_mutation_dict


def get_coverage (bam_filename, mutation):
    """
    Get coverage at a variant location using pysam.
    """

    #print (str(bamfile.count_coverage('18', 60986548-1, 60986548, quality_threshold = 0)))
    #depth_line = pysam.depth("-r","18:60986548-60986548",bam_filename)
    #print(depth_line.rstrip().split('\t')[2])
    #all_depths = list()
    #for mutation in spiked_mutation_dict.keys():
    chrom = mutation[0]
    pos1 = mutation[1]
    location = chrom + ':' + str(pos1) + '-' + str(pos1)
    depth_line = pysam.depth("-r",location,bam_filename)
    #print (mutation)
    #print (depth_line.rstrip().split('\t'))

    split_depth = depth_line.rstrip().split('\t')
    if split_depth[0]:
        depth = split_depth[2]
        return depth
    else:
        return 0


class CommandLine() :
    """
    modified from David Bernick

    Handle the command line, usage and help requests.

    CommandLine uses argparse, now standard in 2.7 and beyond.
    it implements a standard command line argument parser with various argument options,
    a standard usage and help, and an error termination mechanism do-usage_and_die.

    attributes:
    my_command_line.args is a dictionary which includes each of the available command line arguments as
    my_command_line.args['option']
    """

    def __init__(self, inOpts=None) :
        """
        CommandLine constructor.
        Implements a parser to interpret the command line argv string using argparse.
        """
        import argparse
        self.parser = argparse.ArgumentParser(description = 'Program prolog - Specify the input files and conditions',
                                             epilog = 'Program epilog - parameters of infiles must be given.',
                                             add_help = True, #default is True
                                             prefix_chars = '-',
                                             usage = '%(prog)s -t SNP -mf mut.maf -n 200'
                                             )
        self.parser.add_argument('-s','--syntheticVCF', dest='synthetic_filename',
                                 action='store', type=str, required=True,
                                 nargs='+', help='synthetic VCF filenames')
        self.parser.add_argument('-n','--normalVCF', dest='normal_filename',
                                 action='store', type=str, required=True,
                                 nargs='+', help='normal VCF filenames')

        self.parser.add_argument('-ml','--mutationLists', dest='mutation_list',
                                 action='store', type=str, required=True,
                                 help='list of mutations spiked into synthetic data')

        self.parser.add_argument('-pon','--panelOfNormals', dest='pon_filename',
                                 action='store', type=str, required=False,
                                 default='',
                                 help='panel of normal variants fileaname')

        self.parser.add_argument('-b','--bam', dest='bam_filename',
                                 action='store', type=str, required=True,
                                 help='bam location to get coverage')
        """
        self.parser.add_argument('-of','--outputFile', dest='output_file',
                                 action='store',type=str, required=True,
                                 help='output data filename')
        """


        if inOpts is None :
            self.args = self.parser.parse_args()
        else :
            self.args = self.parser.parse_args(inOpts)


def main(my_command_line=None):
    """
    Instantiate VcfComparison class. Load VCFs. Compare detected mutations with
    a known list. Output metrics as graphs.
    """
    my_command_line = CommandLine(my_command_line)

    synthetic_filenames = my_command_line.args.synthetic_filename
    normal_filenames = my_command_line.args.normal_filename
    mutation_list_filename = my_command_line.args.mutation_list
    bam_filename = my_command_line.args.bam_filename
    reference_fasta = '/private/groups/brookslab/reference_indices/hs37/hs37d5.fa'

    file_list = synthetic_filenames + normal_filenames

    spiked_mutation_dict = load_mutation_list(mutation_list_filename, bam_filename)
    print (spiked_mutation_dict)
    cleaned_mutation_dict = clean_mutation_list(spiked_mutation_dict, bam_filename, reference_fasta)
    print (cleaned_mutation_dict)
    vcf_lists = load_all_vcfs(file_list)
    #print (dict_test)
    find_differences(vcf_lists, cleaned_mutation_dict, file_list, bam_filename)


if __name__ == "__main__":
    main()
