#!/usr/bin/env python3
# Name: Jon Akutagawa
# Date: 18-12-28

"""
This script loads VCF files generated by variant callers and compares their
results. Variant callers were fed synthetic data with defined mutations, so
sensitivity and PPV can be measured. Metrics are output as graphs.

input: VCF files generated by paired data runs on MuTect2, Platypus, and/or
VarDict

output:
scatter plot for sensitivity and PPV
histograms for depth and vaf of detected mutations

python calculate_sensitivity_ppv.py -pl /scratch/jakutagawa/icgc/var_calls/platypus/ \
 -vd /scratch/jakutagawa/icgc/var_calls/vardict/ \
 -mt /scratch/jakutagawa/icgc/var_calls/mutect2/ \
 -ml /private/groups/brookslab/jakutagawa/variant_calling/synthetic_mutation_lists/ \
 -pon /scratch/jakutagawa/icgc/bams/gtex/pon/pon.vcf
"""

import sys
from multiprocessing import Pool

import pysam
import os

import numpy as np
import matplotlib
matplotlib.use('Agg')
#import seaborn as sns; sns.set()
import matplotlib.pyplot as plt
import matplotlib.patches as mplpatches
from matplotlib.lines import Line2D


mutect_depths = dict()
dict_test = dict()

def get_matching_bam_filename(mutation_list_filename):
    base_filename = mutation_list_filename.split('/')[-1]
    #print (base_filename)
    matching_normal = '/scratch/jakutagawa/icgc/bams/normal/' + base_filename.strip('.random_snp_only.txt') + '.bam'
    #print (matching_normal)

    return matching_normal


def load_mutation_list (mutation_list_filename):
    """
    Load mutations spiked into the synthetic data
    """
    #bamfile = pysam.AlignmentFile(bam_filename, "rb" )
    counter = 0
    mutations_dict = dict()
    bam_filename = get_matching_bam_filename(mutation_list_filename)
    print (bam_filename)

    for chrom,pos1,pos2,vaf,mut_base,mut_type in read_mutation_list(mutation_list_filename):
        counter += 1
        #new_base = mutation.split('>')[1]
        #mut_entry = (chrom,pos1,pos2,vaf,mut_base,mut_type)
        mut_entry = (chrom,pos1,mut_base)
        depth = get_coverage(bam_filename, mut_entry)
        #depth = 1
        mutations_dict[mut_entry] = (float(vaf), int(depth))
        #mutations_dict[mut_entry] = 1
        #vaf_dict[mut_entry] = vaf
        #if counter % 10000 == 0:
        #    sys.stderr.write('loaded ' + str(counter) + ' mutations \n')
    #print (get_coverage(bam_filename,mut_entry))

    #print (mutations_list[0])
    sys.stderr.write('loaded ' + mutation_list_filename + '\n')
    return mutations_dict

def load_pon (pon_filename):
    """
    Load panel of normals generated by MuTect2
    """
    pon_list = list()
    if pon_filename:
        counter = 0

        for chrom,pos1,ref_base,var_base in read_vcf(pon_filename,'pon'):
            counter += 1
            #new_base = mutation.split('>')[1]
            #mut_entry = (chrom,pos1,ref_base,var_base)
            mut_entry = (chrom,pos1,var_base)
            pon_list.append(mut_entry)
            #if counter % 10000 == 0:
            #    sys.stderr.write('loaded ' + str(counter) + ' mutations \n')

        #print (mutations_list[0])

        #print (mutect_depths)
        #print (dict_test)
        sys.stderr.write('loaded ' + pon_filename + '\n')
        return pon_list
    else:
        sys.stderr.write('no pon specified\n')
        return pon_list


def load_vcf (vcf_filename):
    """
    Load VCF data into a list of tuples
    """
    counter = 0
    mutations_list = list()
    file_origin = get_file_origin(vcf_filename)
    #print ('yoooo')

    for chrom,pos1,ref_base,var_base in read_vcf(vcf_filename,file_origin):
        counter += 1
        #new_base = mutation.split('>')[1]
        #mut_entry = (chrom,pos1,ref_base,var_base)
        mut_entry = (chrom,pos1,var_base)
        mutations_list.append(mut_entry)
        #if counter % 10000 == 0:
        #    sys.stderr.write('loaded ' + str(counter) + ' mutations \n')

    #print (mutations_list[0])

    #print (mutect_depths)
    #print (dict_test)
    sys.stderr.write('loaded ' + vcf_filename + '\n')
    return mutations_list

def get_file_origin(vcf_file):
    """
    Determine which variant caller generated the VCF
    """
    if 'mutect' in vcf_file.lower():
        file_origin = 'mutect'
    elif 'vardict' in vcf_file.lower():
        file_origin = 'vardict'
    elif 'platypus' in vcf_file.lower():
        file_origin = 'platypus'

    return file_origin

def read_vcf (vcf_filename,file_origin):
    """
    Read in VCF and parse line for necessary values.
    """
    #global mutect_depths

    with open(vcf_filename) as fileH:
        # read the header
        print (vcf_filename)
        header_counter = 0
        while True:
            line = fileH.readline()
            header_counter += 1
            if not line.startswith('#'):
                break

        for line in fileH:
            if file_origin == 'vardict':
                split_line = line.rstrip().split(' \t ')
            else:
                split_line = line.rstrip().split('\t')
            chrom = split_line[0]
            try:
                pos1 = int(split_line[1])
            except ValueError:
                continue
                #sys.stderr.write('line begins with &\n')
            ref_base = split_line[3]
            var_base = split_line[4]
            info = split_line[7]
            split_info = info.split(';')


            if file_origin == 'mutect':
                for info_type in split_info:
                    if info_type.split('=')[0] == 'DP':
                        depth = info_type.split('=')[1]
                        #mutect_depths[(chrom,pos1,var_base)] = depth
                        #dict_test[1] = 'yo'
                        #print (depth)
                    if info_type.split('=')[0] == 'TLOD':
                        tlod = float(info_type.split('=')[1].split(',')[0])
                tumor_info = split_line[9]
                split_tumor_info = tumor_info.split(':')

            #if file_origin == 'platypus':



            if not line.startswith('&'):
                #print ('will yield')
                yield chrom,pos1,ref_base,var_base

#sys.stderr.write('loaded ' + str(counter) + ' mutations \n')
def gather_synthetic_mutation_lists (list_folder):
    """
    Read in all synthetic mutation lists from folder using os.walk
    """
    files = list()
    mutation_lists = list()
    for root, dirs, files in os.walk(list_folder):
        for name in files:
            if 'STAR' in name:
                mutation_lists.append((os.path.join(root,name)))

    return mutation_lists

def gather_vcfs (vcf_folder, caller_name):
    """
    Read in all vcfs from folder using os.walk
    """
    files = list()
    vcf_lists = list()
    for root, dirs, files in os.walk(vcf_folder):
        for name in files:
            if name.endswith('.vcf'):
                if caller_name == 'platypus':
                    if 'normal' in name or 'spiked' in name:
                        #print (name)
                        vcf_lists.append((os.path.join(root,name)))
                elif caller_name == 'vardict':
                    if '.out.vcf' in name:
                        vcf_lists.append((os.path.join(root,name)))
                elif caller_name == 'mutect':
                    if ('mutant' or 'normal' in name) and ('idx' not in name) and ('5c149622-df1c-427d-9bf0-fef9a4631b2f' not in name):
                        vcf_lists.append((os.path.join(root,name)))

    return vcf_lists

def load_all_mutation_lists (file_list):
    p = Pool()
    mutation_list_dictionary = dict()

    mutation_lists = p.map(load_mutation_list, file_list)
    for index, file in enumerate(file_list):
        basefile = file.split('/')[-1]
        id = basefile.split('.')[1]
        mutation_list_dictionary[id] = mutation_lists[index]

    return mutation_list_dictionary

def load_all_vcfs (file_list, variant_caller):
    """
    Read in all variants from VCF files simultaneously using Pool
    """
    p = Pool()
    mutant_vcf_dict = dict()
    normal_vcf_dict = dict()
    complete_vcf_trio = list()

    print ('yo')
    print (file_list)
    vcf_lists = p.map(load_vcf, file_list)

    for index, file in enumerate(file_list):
        if variant_caller == 'vardict':
            id = file.split('/')[-2]
        elif variant_caller == 'platypus':
            basefile = file.split('/')[-1]
            id = basefile.split('.')[-3]
        elif variant_caller == 'mutect':
            basefile = file.split('/')[-1]
            id = basefile.split('.')[0]

        if 'spiked' in file:
            mutant_vcf_dict[id] = vcf_lists[index]
        elif 'mutant' in file:
            mutant_vcf_dict[id] = vcf_lists[index]
        elif 'normal' in file:
            normal_vcf_dict[id] = vcf_lists[index]
    print (file_list)
    print (mutant_vcf_dict.keys())
    print (normal_vcf_dict.keys())
    return mutant_vcf_dict, normal_vcf_dict

def read_mutation_list (mutation_list_filename):
    """
    Read in VCF and parse line for necessary values.
    """
    with open(mutation_list_filename) as fileH:
        for line in fileH:
            split_line = line.rstrip().split('\t')
            chrom = split_line[0]
            pos1 = int(split_line[1])
            pos2 = int(split_line[2])
            vaf = split_line[3]
            mut_base = split_line[4]
            mut_type = split_line[5]

            yield chrom,pos1,pos2,vaf,mut_base,mut_type

def calculate_consensus_union_metrics (id_vcf_map):
    combined_sensitivity = list()
    combined_ppv = list()
    combined_origins = list()

    for id, call_dict in id_vcf_map.items():
        if len(call_dict) == 3:
            consensus_true_positives = set(call_dict['platypus'][0])
            consensus_false_positives = set(call_dict['platypus'][1])
            consensus_false_negatives = set(call_dict['platypus'][2])
            union_true_positives = list()
            union_false_positives = list()
            union_false_negatives = list()
            for caller, calls in call_dict.items():
                new_consensus_true_positives = consensus_true_positives & set(call_dict[caller][0])
                new_consensus_false_positives = consensus_false_positives & set(call_dict[caller][1])
                new_consensus_false_negatives = consensus_false_negatives & set(call_dict[caller][2])
                consensus_true_positives = new_consensus_true_positives
                consensus_false_positives = new_consensus_false_positives
                consensus_false_negatives = new_consensus_false_negatives
                union_true_positives += call_dict[caller][0]
                union_false_positives += call_dict[caller][1]
                union_false_negatives += call_dict[caller][2]
        if 'platypus' in call_dict.keys() and 'mutect' in call_dict.keys():
            new_consensus_true_positives = set(call_dict['platypus'][0]) & set(call_dict['mutect'][0])
            new_consensus_false_positives = set(call_dict['platypus'][1]) & set(call_dict['mutect'][1])
            new_consensus_false_negatives = set(call_dict['platypus'][2]) & set(call_dict['mutect'][2])
            consensus_sensitivity = float(len(set(new_consensus_true_positives))) / float(len(set(new_consensus_true_positives))+len(set(new_consensus_false_negatives)))
            consensus_ppv = float(len(set(new_consensus_true_positives))) / float(len(set(new_consensus_true_positives)) + len(set(new_consensus_false_positives)))
            combined_sensitivity.append(consensus_sensitivity)
            combined_ppv.append(consensus_ppv)
            combined_origins.append('platypus_mutect')
        if 'mutect' in call_dict.keys() and 'vardict' in call_dict.keys():
            new_consensus_true_positives = set(call_dict['mutect'][0]) & set(call_dict['vardict'][0])
            new_consensus_false_positives = set(call_dict['mutect'][1]) & set(call_dict['vardict'][1])
            new_consensus_false_negatives = set(call_dict['mutect'][2]) & set(call_dict['vardict'][2])
            consensus_sensitivity = float(len(set(new_consensus_true_positives))) / float(len(set(new_consensus_true_positives))+len(set(new_consensus_false_negatives)))
            consensus_ppv = float(len(set(new_consensus_true_positives))) / float(len(set(new_consensus_true_positives)) + len(set(new_consensus_false_positives)))
            combined_sensitivity.append(consensus_sensitivity)
            combined_ppv.append(consensus_ppv)
            combined_origins.append('mutect_vardict')
        if 'platypus' in call_dict.keys() and 'vardict' in call_dict.keys():
            new_consensus_true_positives = set(call_dict['platypus'][0]) & set(call_dict['vardict'][0])
            new_consensus_false_positives = set(call_dict['platypus'][1]) & set(call_dict['vardict'][1])
            new_consensus_false_negatives = set(call_dict['platypus'][2]) & set(call_dict['vardict'][2])
            consensus_sensitivity = float(len(set(new_consensus_true_positives))) / float(len(set(new_consensus_true_positives))+len(set(new_consensus_false_negatives)))
            consensus_ppv = float(len(set(new_consensus_true_positives))) / float(len(set(new_consensus_true_positives)) + len(set(new_consensus_false_positives)))
            combined_sensitivity.append(consensus_sensitivity)
            combined_ppv.append(consensus_ppv)
            combined_origins.append('platypus_vardict')

        consensus_sensitivity = float(len(set(consensus_true_positives))) / float(len(set(consensus_true_positives))+len(set(consensus_false_negatives)))
        consensus_ppv = float(len(set(consensus_true_positives))) / float(len(set(consensus_true_positives)) + len(set(consensus_false_positives)))
        combined_sensitivity.append(consensus_sensitivity)
        combined_ppv.append(consensus_ppv)
        combined_origins.append('consensus')
        union_sensitivity = float(len(set(union_true_positives))) / float(len(set(union_true_positives))+len(set(union_false_negatives)))
        union_ppv = float(len(set(union_true_positives))) / float(len(set(union_true_positives)) + len(set(union_false_positives)))
        combined_sensitivity.append(union_sensitivity)
        combined_ppv.append(union_ppv)
        combined_origins.append('union')

    return combined_sensitivity, combined_ppv, combined_origins




def calculate_sensitivity_ppv (vardict_vcfs, platypus_vcfs, mutect_vcfs, cleaned_mutation_dict, pon_list):
    """
    Determine which variant calls are true and false positives. Prints
    sensitivity and PPV.
    """
    #pairs = len(vcf_lists) / 2
    file_origins = list()
    ppv_list = list()
    sensitivity_list = list()
    id_list = vardict_vcfs[0].keys()
    vcf_caller_name_map = {'vardict':vardict_vcfs,'platypus':platypus_vcfs,'mutect':mutect_vcfs}
    caller_variant_map = {'vardict':[],'platypus':[],'mutect':[]}
    id_vcf_map = dict()

    for caller, vcfs in vcf_caller_name_map.items():
        for id in id_list:
            try:
                spiked_mutation_list = vcfs[0][id]
                normal_mutation_list = vcfs[1][id]
                print ('total mutant calls: ' + str(len(spiked_mutation_list)))
                print ('total normal calls: ' + str(len(normal_mutation_list)))
                false_negatives = list()
                possible_positives = list()
                false_positives = list()
                true_positives = list()
                filtered_true_positives = list()
                filtered_false_positives  = list()
                filtered_possible_positives = list()

                false_negatives = list(set(cleaned_mutation_dict[id]) - set(spiked_mutation_list))
                possible_positives = list(set(spiked_mutation_list) - set(normal_mutation_list))
                for positive in possible_positives:
                    caller_variant_map[caller].append(positive)
                    if positive in cleaned_mutation_dict[id]:
                        true_positives.append(positive)

                    else:
                        #print (get_coverage(bam_filename,positive))
                        false_positives.append(positive)

                print (caller)
                print (len(cleaned_mutation_dict[id]))
                print (len(false_negatives))
                print (len(possible_positives))
                print (len(true_positives))
                print (len(false_positives))
                ppv = float(len(true_positives)) / float(len(true_positives) + len(false_positives))
                ppv_list.append(ppv)
                sensitivity = float(len(true_positives)) / float(len(true_positives)+len(false_negatives))
                sensitivity_list.append(sensitivity)
                #file_origin = get_file_origin(file_list[index])
                file_origins.append(caller)


                if pon_list:
                    filtered_possible_positives = list(set(spiked_mutation_list) - set(normal_mutation_list) - set(pon_list))
                    for positive in filtered_possible_positives:
                        if positive in cleaned_mutation_dict[id]:
                            filtered_true_positives.append(positive)
                        else:
                            #print (get_coverage(bam_filename,positive))
                            filtered_false_positives.append(positive)
                    ppv = float(len(filtered_true_positives)) / float(len(filtered_true_positives) + len(filtered_false_positives))
                    ppv_list.append(ppv)
                    sensitivity = float(len(filtered_true_positives)) / float(len(filtered_true_positives)+len(false_negatives))
                    sensitivity_list.append(sensitivity)
                    #file_origin = get_file_origin(file_list[index])
                    file_origins.append(caller+'_filter')
                    print (caller+'_filter')
                    print (len(filtered_possible_positives))
                    print (len(filtered_true_positives))
                    print (len(filtered_false_positives))

                try:
                    id_vcf_map[id][caller] = [filtered_true_positives, filtered_false_positives, false_negatives]
                except KeyError:
                    id_vcf_map[id] = {caller:[filtered_true_positives, filtered_false_positives, false_negatives]}

                print (id)
            except KeyError:
                pass

            """
            try:
                spiked_mutation_list = platypus_vcfs[0][id]
                normal_mutation_list = platypus_vcfs[1][id]
                print ('total mutant calls: ' + str(len(spiked_mutation_list)))
                print ('total normal calls: ' + str(len(normal_mutation_list)))
                false_negatives = list()
                possible_positives = list()
                false_positives = list()
                true_positives = list()
                filtered_true_positives = list()
                filtered_false_positives  = list()
                filtered_possible_positives = list()

                false_negatives = list(set(cleaned_mutation_dict[id]) - set(spiked_mutation_list))
                possible_positives = list(set(spiked_mutation_list) - set(normal_mutation_list))
                for positive in possible_positives:
                    if positive in cleaned_mutation_dict[id]:
                        true_positives.append(positive)
                    else:
                        #print (get_coverage(bam_filename,positive))
                        false_positives.append(positive)
                print ('platypus')
                print (len(cleaned_mutation_dict[id]))
                print (len(false_negatives))
                print (len(possible_positives))
                print (len(true_positives))
                print (len(false_positives))
                ppv = float(len(true_positives)) / float(len(true_positives) + len(false_positives))
                ppv_list.append(ppv)
                sensitivity = float(len(true_positives)) / float(len(true_positives)+len(false_negatives))
                sensitivity_list.append(sensitivity)
                #file_origin = get_file_origin(file_list[index])
                file_origins.append('platypus')

                if pon_list:
                    filtered_possible_positives = list(set(spiked_mutation_list) - set(normal_mutation_list) - set(pon_list))
                    for positive in filtered_possible_positives:
                        if positive in cleaned_mutation_dict[id]:
                            filtered_true_positives.append(positive)
                        else:
                            #print (get_coverage(bam_filename,positive))
                            filtered_false_positives.append(positive)
                    ppv = float(len(filtered_true_positives)) / float(len(filtered_true_positives) + len(filtered_false_positives))
                    ppv_list.append(ppv)
                    sensitivity = float(len(filtered_true_positives)) / float(len(filtered_true_positives)+len(false_negatives))
                    sensitivity_list.append(sensitivity)
                    #file_origin = get_file_origin(file_list[index])
                    file_origins.append('platypus_filter')
                    print ('platypus_filter')
                    #print (len(cleaned_mutation_dict[id]))
                    #print (len(false_negatives))
                    print (len(filtered_possible_positives))
                    print (len(filtered_true_positives))
                    print (len(filtered_false_positives))
            except KeyError:
                pass
            """


        """

        """


        """


        print ('sensitivity: ' + str(sensitivity))
        print ('ppv: ' + str(ppv))
        print ('false pos count: ' + str(len(false_positives)))

        #vaf_depth_histograms (spiked_mutation_dict, true_positives, false_negatives, false_positives, file_origin, bam_filename)
        """

    combined_sensitivity, combined_ppv, combined_file_origins = calculate_consensus_union_metrics (id_vcf_map)
    sensitivity_list += combined_sensitivity
    ppv_list += combined_ppv
    file_origins += combined_file_origins
    plot_sensitivity_ppv(sensitivity_list, ppv_list, file_origins)


def vaf_depth_histograms (spiked_mutation_dict, true_positives, false_negatives, false_positives, file_origin, bam_filename):
    """
    Output histograms showing vaf and depth of true positive and false negative
    mutations using matplotlib.
    """
    true_positive_vaf_list = list()
    false_negative_vaf_list = list()
    true_positive_depth_list = list()
    false_negative_depth_list = list()
    false_positive_depth_list = list()
    my_bins = np.arange(1, 501, step=25)
    my_log_bins = np.logspace(0,3,num=15,base=10)

    for mutation in true_positives:
        true_positive_vaf_list.append(spiked_mutation_dict[mutation][0])
        true_positive_depth_list.append(spiked_mutation_dict[mutation][1])

    for mutation in false_negatives:
        false_negative_vaf_list.append(spiked_mutation_dict[mutation][0])
        false_negative_depth_list.append(spiked_mutation_dict[mutation][1])

    for mutation in false_positives:
        depth = int(get_coverage(bam_filename, mutation))
        #if depth == 0:
        #    depth += 1
        #log_depth = np.log10(depth)
        false_positive_depth_list.append(depth)

    #print (false_positive_depth_list)

    #print ('yo')
    plt.figure(figsize=(6,3))
    panel1=plt.axes([0.05,0.175,2.25/6,2.275/3])
    panel2=plt.axes([0.55,0.175,2.25/6,2.275/3])
    #x_array_hist, bins = np.histogram(true_positive_depth_list, bins=11)
    #print (true_positive_depth_list)
    #print (x_array_hist)
    #print (bins)

    """
    x_array_hist, bins = np.histogram(vaf_list, bins=11)
    #print (x_array_hist)
    #print (bins)

    for step in np.arange(0,len(x_array_hist),1):
        left=bins[step]
        bottom=0
        width=bins[step+1]-bins[step]
        height=x_array_hist[step]

        rectangle1=mplpatches.Rectangle((left,bottom),width,height,\
                                        linewidth=0.1,\
                                        facecolor=(0.5,0.5,0.5),\
                                        edgecolor=(0,0,0))



        panel1.add_patch(rectangle1)
    """
    panel1.hist(true_positive_vaf_list, bins = 11, label = 'true positive')
    panel1.hist(false_negative_vaf_list, bins = 11, alpha = 0.5, label = 'false negative')
    panel2.hist(true_positive_depth_list, bins = my_log_bins, label = 'true positive')
    panel2.hist(false_negative_depth_list, bins = my_log_bins, alpha = 0.5, label = 'false negative')
    panel2.hist(false_positive_depth_list, bins = my_log_bins, alpha = 0.5, label = 'false positive')


    panel1.set_xlabel('vaf')
    panel2.set_xlabel('depth')
    panel2.legend(loc='upper right')
    panel2.set_xticks([1,10,100,1000])
    panel2.set_xticklabels([1,10,100,1000])
    #print(panel1.get_xticks)
    #print(panel1.get_xticklabels)

    plot_filename = file_origin + '_histograms-log.pdf'
    plt.savefig(plot_filename)


def plot_sensitivity_ppv (sensitivity_list, ppv_list, file_origins):
    """
    Output a scatter plot comparing sensitivity and PPV of each tool.
    """
    plt.figure(figsize=(3,3))
    panel1=plt.axes([0.2,0.175,2.25/3,2.275/3])
    print (sensitivity_list)
    print (ppv_list)
    print (file_origins)
    palette = ['red','blue','green','#ff6666','#66ff66','#ffff00','#ff0066','#9933ff','#ff8000','#000000']
    labels = ['vardict_filter','platypus_filter','mutect_filter','vardict',
              'platypus','mutect','platypus_mutect','mutect_vardict', 'platypus_vardict',
              'union','consensus']
    colors = list()
    for origin in file_origins:
        if origin == labels[0]:
            colors.append(palette[0])
        elif origin == labels[1]:
            colors.append(palette[1])
        elif origin == labels[2]:
            colors.append(palette[2])
        elif origin == labels[3]:
            colors.append(palette[3])
        elif origin == labels[4]:
            colors.append(palette[4])
        elif origin == labels[5]:
            colors.append(palette[5])
        elif origin == labels[6]:
            colors.append(palette[6])
        elif origin == labels[7]:
            colors.append(palette[7])
        elif origin == labels[8]:
            colors.append(palette[8])
        elif origin == labels[9]:
            colors.append(palette[9])
        elif origin == labels[10]:
            colors.append(palette[10])

    #print (colors)
    #print (sensitivity_list[34:43])
    #print (ppv_list[34:43])
    #print (file_origins[34:43])
    #print (colors[34:43])


    panel1.scatter(sensitivity_list, ppv_list, alpha = 0.5, c = colors, label = file_origins)

    #for index, point in enumerate(sensitivity_list):
        #panel1.scatter(sensitivity_list[index], ppv_list[index], alpha = 0.5, c = colors[index], label = file_origins[index])
        #for index, origin in enumerate(file_origins,0):
            #panel1.text(sensitivity_list[index]*1.1, ppv_list[index], origin,
            #            fontsize=8,
            #            horizontalalignment='left',
            #            verticalalignment='center')
    panel1.set_xlabel('sensitivity')
    panel1.set_ylabel('ppv')
    ticks = np.arange(0, 1.1, step=0.25)
    panel1.set_xticks(ticks)
    panel1.set_yticks(ticks)
    panel1.set_xticklabels(ticks)
    panel1.set_yticklabels(ticks)

    legend_dots = list()
    for color in palette:
        legend_dots.append(Line2D([0], [0], marker='o', color='w', alpha = 0.5,
                              markerfacecolor=color, markersize=4))
    """
    custom_dots = [Line2D([0], [0], marker='o', color='w', alpha = 0.5,
                          markerfacecolor='r', markersize=5),
                   Line2D([0], [0], marker='o', color='w', alpha = 0.5,
                   markerfacecolor='b', markersize=5),
                   Line2D([0], [0], marker='o', color='w', alpha = 0.5,
                   markerfacecolor='g', markersize=5),
                   Line2D([0], [0], marker='o', color='w', alpha = 0.5,
                   markerfacecolor='#ff8000', markersize=5),
                   Line2D([0], [0], marker='o', color='w', alpha = 0.5,
                   markerfacecolor='#000000', markersize=5)]
    """
    panel1.legend(legend_dots,labels,loc='lower left', fontsize = 'x-small', fancybox=True, framealpha=0.5)
    
    plt.savefig('sensitivity_vs_ppv.pdf')

def clean_mutation_list (all_mutations_dict, reference_fasta):
    """
    Remove mutations that have the same base as the spiked mutation
    """
    cleaned_all_mutations_dict = dict()
    all_removed_mutations_dict = dict()

    for id, mutation_dict in all_mutations_dict.items():
        cleaned_mutation_dict = dict()
        removed_mutations = list()
        for mutation, vaf_depth in mutation_dict.items():
            chrom = mutation[0]
            pos1 = mutation[1]
            #pos2 = mutation[2]
            mut_base = mutation[2]
            location = chrom + ':' + str(pos1) + '-' + str(pos1)
            #pileup = pysam.mpileup("-O","-r", location, "-f", reference_fasta, bam_filename)
            faidx = pysam.faidx(reference_fasta, location)

            #print (pileup)
            #mutation_depth = pysam.depth("-r", location, bam_filename)
            mutation_depth = vaf_depth[1]
            #print ('for mutation: ' + str(mutation))
            #try:
            #    depth = mutation_depth.rstrip().split('\t')[2]
            #except IndexError:
            #    depth = 0

            ref_base = faidx.rstrip().split('\n')[1]
            #try:
            #    ref_base = pileup.rstrip().split('\t')[2]
            #except IndexError:
            #    ref_base = 0

            #print ('base')
            #print (ref_base)
            #print (mut_base)
            #print (depth)
            if mut_base == ref_base or mutation_depth == 0 or ref_base == 0:
                removed_mutations.append(mutation)
            else:
                cleaned_mutation_dict[mutation] = vaf_depth

        cleaned_all_mutations_dict[id] = cleaned_mutation_dict
        all_removed_mutations_dict[id] = removed_mutations
        sys.stderr.write('removed ' + str(len(removed_mutations)) + ' mutations with 0 reads or trivial mutation\n')
    return cleaned_all_mutations_dict


def get_coverage (bam_filename, mutation):
    """
    Get coverage at a variant location using pysam.
    """

    #print (str(bamfile.count_coverage('18', 60986548-1, 60986548, quality_threshold = 0)))
    #depth_line = pysam.depth("-r","18:60986548-60986548",bam_filename)
    #print(depth_line.rstrip().split('\t')[2])
    #all_depths = list()
    #for mutation in spiked_mutation_dict.keys():
    chrom = mutation[0]
    pos1 = mutation[1]
    location = chrom + ':' + str(pos1) + '-' + str(pos1)
    depth_line = pysam.depth("-r",location,bam_filename)
    #print (mutation)
    #print (depth_line.rstrip().split('\t'))

    split_depth = depth_line.rstrip().split('\t')
    if split_depth[0]:
        depth = split_depth[2]
        return depth
    else:
        return 0


class CommandLine() :
    """
    modified from David Bernick

    Handle the command line, usage and help requests.

    CommandLine uses argparse, now standard in 2.7 and beyond.
    it implements a standard command line argument parser with various argument options,
    a standard usage and help, and an error termination mechanism do-usage_and_die.

    attributes:
    my_command_line.args is a dictionary which includes each of the available command line arguments as
    my_command_line.args['option']
    """

    def __init__(self, inOpts=None) :
        """
        CommandLine constructor.
        Implements a parser to interpret the command line argv string using argparse.
        """
        import argparse
        self.parser = argparse.ArgumentParser(description = 'Program prolog - Specify the input files and conditions',
                                             epilog = 'Program epilog - parameters of infiles must be given.',
                                             add_help = True, #default is True
                                             prefix_chars = '-',
                                             usage = '%(prog)s -t SNP -mf mut.maf -n 200'
                                             )
        """
        self.parser.add_argument('-s','--syntheticVCF', dest='synthetic_filename',
                                 action='store', type=str, required=True,
                                 nargs='+', help='synthetic VCF filenames')
        self.parser.add_argument('-n','--normalVCF', dest='normal_filename',
                                 action='store', type=str, required=True,
                                 nargs='+', help='normal VCF filenames')
        """

        self.parser.add_argument('-pl','--platypusFolder', dest='platypus_folder',
                                 action='store', type=str, required=False,
                                 default=None,
                                 help='location of platypus vcf files')
        self.parser.add_argument('-vd','--vardictFolder', dest='vardict_folder',
                                 action='store', type=str, required=False,
                                 default=None,
                                 help='location of vardict vcf files')
        self.parser.add_argument('-mt','--mutectFolder', dest='mutect_folder',
                                 action='store', type=str, required=False,
                                 default=None,
                                 help='location of mutect vcf files')

        self.parser.add_argument('-ml','--mutationLists', dest='mutation_list_folder',
                                 action='store', type=str, required=True,
                                 help='list of mutations spiked into synthetic data')

        self.parser.add_argument('-pon','--panelOfNormals', dest='pon_filename',
                                 action='store', type=str, required=False,
                                 default=None,
                                 help='panel of normal variants fileaname')

        self.parser.add_argument('-b','--bam', dest='bam_filename',
                                 action='store', type=str, required=False,
                                 help='bam location to get coverage')
        """
        self.parser.add_argument('-of','--outputFile', dest='output_file',
                                 action='store',type=str, required=True,
                                 help='output data filename')
        """


        if inOpts is None :
            self.args = self.parser.parse_args()
        else :
            self.args = self.parser.parse_args(inOpts)


def main(my_command_line=None):
    """
    Instantiate VcfComparison class. Load VCFs. Compare detected mutations with
    a known list. Output metrics as graphs.
    """
    my_command_line = CommandLine(my_command_line)

    #synthetic_filenames = my_command_line.args.synthetic_filename
    #normal_filenames = my_command_line.args.normal_filename
    #mutation_list_filename = my_command_line.args.mutation_list
    #bam_filename = my_command_line.args.bam_filename
    synthetic_mutation_lists_folder = my_command_line.args.mutation_list_folder
    platypus_folder = my_command_line.args.platypus_folder
    vardict_folder = my_command_line.args.vardict_folder
    mutect_folder = my_command_line.args.mutect_folder
    pon_filename = my_command_line.args.pon_filename
    reference_fasta = '/private/groups/brookslab/reference_indices/hs37/hs37d5.fa'

    #file_list = synthetic_filenames + normal_filenames

    synthetic_mutation_lists = gather_synthetic_mutation_lists(synthetic_mutation_lists_folder)
    pon_list = load_pon(pon_filename)

    spiked_mutation_dict = load_all_mutation_lists(synthetic_mutation_lists)
    #print (synthetic_mutation_lists)
    #print (spiked_mutation_dict)
    cleaned_mutation_dict = clean_mutation_list(spiked_mutation_dict, reference_fasta)
    #print (cleaned_mutation_dict.keys())

    if platypus_folder:
        platypus_vcf_list = gather_vcfs(platypus_folder, 'platypus')
        #print (platypus_vcf_list)
        platypus_vcfs = load_all_vcfs(platypus_vcf_list, 'platypus')
        #print (platypus_vcf_list)
    if vardict_folder:
        mutant_folder = vardict_folder + 'spiked/'
        #print (mutant_folder)
        normal_folder = vardict_folder + 'normal/'
        #print (normal_folder)
        vardict_vcf_list = gather_vcfs(mutant_folder, 'vardict')
        vardict_vcf_list += gather_vcfs(normal_folder, 'vardict')
        #print (vardict_vcf_list)
        #print (len(vardict_vcf_list))

        vardict_vcfs = load_all_vcfs(vardict_vcf_list, 'vardict')
        #print (len (vardict_vcfs))
        #print (len (vardict_vcfs[0]))
    if mutect_folder:
        mutect_vcf_list = gather_vcfs(mutect_folder, 'mutect')
        mutect_vcfs = load_all_vcfs(mutect_vcf_list, 'mutect')



    #print (mutect_vcfs[0]['PCAWG'])

    calculate_sensitivity_ppv(vardict_vcfs, platypus_vcfs, mutect_vcfs, cleaned_mutation_dict, pon_list)


if __name__ == "__main__":
    main()
